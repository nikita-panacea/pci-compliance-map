{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44c7d2-5e1d-437c-9f52-645f0404b874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF and loading cached sections...\n",
      "Loaded cached processed PDF sections.\n",
      "Found sections:\n",
      "--- General ---\n",
      "--- PCI DSS 4.0 ---\n",
      "--- DO: ---\n",
      "--- DON’T: ---\n",
      "--- DSS. ---\n",
      "--- OR • ---\n",
      "--- CDE. ---\n",
      "--- IDS/IPS. ---\n",
      "--- FIM. ---\n",
      "--- OR ---\n",
      "Extracting OCR text from image...\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "No mapped controls found for the given image. Exiting.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from mimetypes import guess_type\n",
    "from PIL import Image\n",
    "import fitz\n",
    "import pytesseract\n",
    "import tiktoken\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Set your OpenAI API key \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "client = OpenAI(organization='', project='', api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# File names for caching\n",
    "CHUNKS_CACHE_FILE = \"pci_processed_chunks.json\"\n",
    "TOKEN_THRESHOLD = 10000\n",
    "\n",
    "# --------------------------\n",
    "# PDF Partitioning and Caching\n",
    "# --------------------------\n",
    "\n",
    "def partition_pdf_by_title(pdf_path):\n",
    "    \"\"\"\n",
    "    Use unstructured to partition the PDF into sections based on titles/headers.\n",
    "    Returns a dict mapping section titles to their full text.\n",
    "    \"\"\"\n",
    "    elements = partition_pdf(filename=pdf_path)\n",
    "    sections = {}\n",
    "    current_title = \"General\"\n",
    "    sections[current_title] = \"\"\n",
    "    for element in elements:\n",
    "        text = element.text.strip()\n",
    "        # Use getattr to safely access metadata (which is not a dict)\n",
    "        category = getattr(element.metadata, \"category\", \"\") if element.metadata else \"\"\n",
    "        if category in [\"Title\", \"Header\"] or (text and text.isupper() and len(text.split()) < 10):\n",
    "            current_title = text\n",
    "            if current_title not in sections:\n",
    "                sections[current_title] = \"\"\n",
    "        else:\n",
    "            sections[current_title] += \"\\n\" + text\n",
    "    return sections\n",
    "\n",
    "def count_tokens(text: str, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"Count tokens using tiktoken for a given model.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def split_text_into_chunks(text: str, max_tokens: int = TOKEN_THRESHOLD, overlap: int = 100) -> list:\n",
    "    \"\"\"\n",
    "    Split a long text into overlapping chunks based on token count.\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = start + max_tokens\n",
    "        chunk = encoding.decode(tokens[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap  # maintain overlap for context continuity\n",
    "    return chunks\n",
    "\n",
    "def process_pdf_sections(pdf_path):\n",
    "    \"\"\"\n",
    "    Partition the PDF by title and, for each section that exceeds TOKEN_THRESHOLD,\n",
    "    further split it into sub-chunks.\n",
    "    Returns a dictionary mapping section titles to lists of text chunks.\n",
    "    \"\"\"\n",
    "    raw_sections = partition_pdf_by_title(pdf_path)\n",
    "    processed_sections = {}\n",
    "    for title, content in raw_sections.items():\n",
    "        full_section = f\"{title}\\n{content}\"\n",
    "        tokens = count_tokens(full_section)\n",
    "        if tokens > TOKEN_THRESHOLD:\n",
    "            print(f\"Section '{title}' is very large ({tokens} tokens); splitting further.\")\n",
    "            sub_chunks = split_text_into_chunks(full_section, max_tokens=TOKEN_THRESHOLD, overlap=100)\n",
    "            processed_sections[title] = sub_chunks\n",
    "        else:\n",
    "            processed_sections[title] = [full_section]\n",
    "    return processed_sections\n",
    "\n",
    "def load_or_process_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Load cached processed PDF sections if available; otherwise, process the PDF and cache the result.\n",
    "    \"\"\"\n",
    "    if os.path.exists(CHUNKS_CACHE_FILE):\n",
    "        with open(CHUNKS_CACHE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            processed_sections = json.load(f)\n",
    "        print(\"Loaded cached processed PDF sections.\")\n",
    "    else:\n",
    "        processed_sections = process_pdf_sections(pdf_path)\n",
    "        with open(CHUNKS_CACHE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(processed_sections, f, ensure_ascii=False, indent=2)\n",
    "        print(\"Processed PDF and saved cache.\")\n",
    "    return processed_sections\n",
    "\n",
    "# --------------------------\n",
    "# Image and OCR Utilities\n",
    "# --------------------------\n",
    "\n",
    "def ocr_image(image_path):\n",
    "    \"\"\"Extract text from an image using pytesseract.\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    return pytesseract.image_to_string(image)\n",
    "\n",
    "def image_to_data_url(image_path: str) -> str:\n",
    "    \"\"\"Convert an image file to a base64-encoded data URL.\"\"\"\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'application/octet-stream'\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        encoded = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    return f\"data:{mime_type};base64,{encoded}\"\n",
    "\n",
    "# --------------------------\n",
    "# Token Counting Utility\n",
    "# --------------------------\n",
    "\n",
    "def count_tokens(text: str, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"Count tokens using tiktoken for a given model.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def split_text_into_chunks(text: str, max_tokens: int = TOKEN_THRESHOLD, overlap: int = 100) -> list:\n",
    "    \"\"\"\n",
    "    Split a long text into overlapping chunks based on token count.\n",
    "    Uses tiktoken for accurate token counting.\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = start + max_tokens\n",
    "        chunk = encoding.decode(tokens[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap  # add overlap for context continuity\n",
    "    return chunks\n",
    "# --------------------------\n",
    "# Relevance Check for Each Chunk\n",
    "# --------------------------\n",
    "\n",
    "def check_chunk_relevance(chunk_text: str, image_query: str) -> bool:\n",
    "    \"\"\"\n",
    "    Ask GPT-4 if a given chunk (section) is relevant to the client's image.\n",
    "    Returns True if the answer starts with \"yes\".\n",
    "    \"\"\"\n",
    "    system_message = f\"\"\"\n",
    "    You are an expert in PCI-DSS compliance. \n",
    "    You are given a section extracted from the PCI-DSS Report on Compliance Template containing the controls and requirements.\n",
    "    A client has provided a screenshot showing details of their network and security configuration.\n",
    "    Analyze the image and identify which specific control requirement is being addressed.\n",
    "    Please be specific in your mapping.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in PCI-DSS compliance.\n",
    "    Below is a section from the PCI-DSS Report on Compliance Template:\n",
    "    \n",
    "    \\\"\\\"\\\"{chunk_text}\\\"\\\"\\\"\n",
    "    \n",
    "    Also, consider the following text extracted from a client's screenshot:\n",
    "    \\\"\\\"\\\"{image_query}\\\"\\\"\\\"\n",
    "\n",
    "    Task:\n",
    "    1. Does this image provide evidence for a specific control(s) and/or \n",
    "    requirements in this section?\n",
    "    2. Identify the EXACT control references from text.\n",
    "    3. Match image features to control requirements.\n",
    "\n",
    "    Is this section relevant to mapping the client's network/security information (from the screenshot) to a PCI-DSS control?\n",
    "    Identify if the image shows implementation of ANY control from this section.\n",
    "     \n",
    "    Answer with a single word: \"Yes\" or \"No\".\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\", \n",
    "            messages=messages,\n",
    "            max_tokens=10,\n",
    "            temperature=0  # deterministic\n",
    "        )\n",
    "        answer = response.choices[0].message.content.strip().lower()\n",
    "        return answer.startswith(\"yes\")\n",
    "    except Exception as e:\n",
    "        print(f\"Relevance check error: {e}\")\n",
    "        return False\n",
    "\n",
    "# --------------------------\n",
    "# Final Mapping Call\n",
    "# --------------------------\n",
    "\n",
    "def map_chunk_to_control(aggregated_context: str, image_path: str, image_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Use the aggregated context (all relevant sections), the OCR text, and the image\n",
    "    to have GPT-4 Vision map the screenshot to specific PCI-DSS rule(s).\n",
    "    \"\"\"\n",
    "    system_message = f\"\"\"\n",
    "    You are an expert in PCI-DSS compliance. \n",
    "    You are given a section extracted from the PCI-DSS Report on Compliance Template containing the controls and requirements.\n",
    "    A client has provided a screenshot showing details of their network and security configuration.\n",
    "    Analyze the image and identify which specific control requirement is being addressed.\n",
    "    Please be specific in your mapping.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in PCI-DSS compliance.\n",
    "    Below is the full context from the PCI-DSS Report on Compliance Template (all sections containing specific rules):\n",
    "    {aggregated_context}\n",
    "    \n",
    "    Also, here is text extracted from a client's network/security screenshot:\n",
    "    {image_text}\n",
    "    \n",
    "    Provide only \n",
    "    1. The control requirement code(s) (e.g., \"Requirement 1.1.1\"), \n",
    "    2. The description of the requirement/control from the chunk section provided.\n",
    "    3. A brief explanation on why the image satifies the requirement in the chunk section.\n",
    "    \n",
    "    Provide answer in the format:\n",
    "    \n",
    "    Req.: 'requirement/control code'\n",
    "    desp: 'description of requirement'\n",
    "    expn: 'explantion'\n",
    "    \n",
    "    Do not include any extraneous text.\n",
    "    \"\"\"\n",
    "    image_data_url = image_to_data_url(image_path)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": image_data_url}}\n",
    "        ]}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  \n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# --------------------------\n",
    "# Main Application Flow\n",
    "# --------------------------\n",
    "\n",
    "def main():\n",
    "    pdf_path = \"PCI-DSS-ROC-Template.pdf\"       # Path to your PCI-DSS ROC PDF\n",
    "    image_path = \"Connfido Network Diagram.png\"  # Client screenshot image path\n",
    "\n",
    "    print(\"Processing PDF and loading cached sections...\")\n",
    "    processed_sections = load_or_process_pdf(pdf_path)\n",
    "    if not processed_sections:\n",
    "        print(\"No processed sections found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"Found sections:\")\n",
    "    for title in processed_sections:\n",
    "        print(f\"--- {title} ---\")\n",
    "\n",
    "    print(\"Extracting OCR text from image...\")\n",
    "    image_query = ocr_image(image_path)\n",
    "\n",
    "    mapped_controls = []\n",
    "    # Loop over each section and its sub-chunks\n",
    "    for title, chunk_list in processed_sections.items():\n",
    "        for chunk in chunk_list:\n",
    "            # Check if this chunk is relevant\n",
    "            if check_chunk_relevance(chunk, image_query):\n",
    "                print(f\"Chunk from section '{title}' is relevant. Mapping control...\")\n",
    "                mapping = map_chunk_to_control(chunk, image_path, image_query)\n",
    "                if mapping:\n",
    "                    mapped_controls.append(mapping)\n",
    "\n",
    "    if not mapped_controls:\n",
    "        print(\"No mapped controls found for the given image. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Aggregate only the mapping outputs (control codes and explanations)\n",
    "    aggregated_mapping = \"\\n\".join(mapped_controls)\n",
    "    print(\"Aggregated Mapped Controls:\")\n",
    "    print(aggregated_mapping)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4d6e54c-f53f-4b32-8f46-e3b74df7e3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF and loading cached sections...\n",
      "Loaded cached processed PDF sections.\n",
      "Found sections:\n",
      "--- General ---\n",
      "--- PCI DSS 4.0 ---\n",
      "--- DO: ---\n",
      "--- DON’T: ---\n",
      "--- DSS. ---\n",
      "--- OR • ---\n",
      "--- CDE. ---\n",
      "--- IDS/IPS. ---\n",
      "--- FIM. ---\n",
      "--- OR ---\n",
      "Extracting OCR text from image...\n",
      "Chunk from section 'General' is relevant. Mapping control...\n",
      "Chunk from section 'PCI DSS 4.0' is relevant. Mapping control...\n",
      "Chunk from section 'DO:' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'OR •' is relevant. Mapping control...\n",
      "Chunk from section 'OR •' is relevant. Mapping control...\n",
      "Chunk from section 'OR •' is relevant. Mapping control...\n",
      "Chunk from section 'CDE.' is relevant. Mapping control...\n",
      "Chunk from section 'CDE.' is relevant. Mapping control...\n",
      "Chunk from section 'IDS/IPS.' is relevant. Mapping control...\n",
      "Chunk from section 'IDS/IPS.' is relevant. Mapping control...\n",
      "Chunk from section 'FIM.' is relevant. Mapping control...\n",
      "Chunk from section 'OR' is relevant. Mapping control...\n",
      "Chunk from section 'OR' is relevant. Mapping control...\n",
      "Chunk from section 'OR' is relevant. Mapping control...\n",
      "Aggregated Mapped Controls:\n",
      "Requirement 1.1.3: Network diagrams include all connections to cardholder data, and critical components for PCI DSS compliance.\n",
      "\n",
      "Requirement 4.1: Use strong cryptography and security protocols (e.g., TLS v1.2 or above) to safeguard sensitive cardholder data during transmission.\n",
      "Requirement 1.1.3\n",
      "\n",
      "Network Diagram - The diagram shows the segmentation of the network with components such as Virtual Networks (VNET), Load Balancers, and specific IP ranges, which addresses the requirement to diagram all network connections to cardholder data (CDE).\n",
      "Requirement 1.1.2\n",
      "\n",
      "The network diagram provided is an example of a current diagram that accurately reflects the cardholder data flows and security zones, as required by the PCI-DSS for understanding data flows and connections.\n",
      "Requirement 1.1.3: The network diagram in the screenshot shows the connectivity, which addresses having current network diagrams that identify all connections between the cardholder data environment and other networks, including any wireless networks.\n",
      "Requirement 1.2.3\n",
      "\n",
      "The network diagram shows all connections between the Cardholder Data Environment (CDE) and other networks, which addresses the requirement to maintain accurate network diagrams.\n",
      "Requirement 2.2.7\n",
      "\n",
      "Non-console administrative access is encrypted using strong cryptography (e.g., TLS v1.2 or above).\n",
      "Requirement 3.4.1: The diagram indicates the use of masking and protecting PAN (Primary Account Number) data through TLS v1.2, showing compliance with secure transmission and access control within a secure network.\n",
      "Requirement 4.1.1: The network diagram indicates usage of TLS v1.2 or above for secure transmission, aligning with the requirement for strong cryptography during data transmission.\n",
      "Requirement 6.4.1\n",
      "\n",
      "The network diagram showing the use of TLS v1.2 or above for secure communication is related to protecting public-facing web applications against known attacks and vulnerabilities.\n",
      "Requirement 6.4.1\n",
      "\n",
      "The network diagram shows the deployment of automated technical solutions that detect and block web-based attacks in front of public-facing web applications, satisfying the requirement to protect such applications.\n",
      "Requirement 8.1.2\n",
      "\n",
      "Explanation: The network diagram indicates segregation of roles and responsibilities, aligning with documentation and assignment of these roles as per PCI DSS Requirement 8.1.2.\n",
      "Requirement 1.2.1\n",
      "\n",
      "Explanation: The diagram involves the use of network segmentation through virtual networks (VNETs) and network security groups (NSGs), restricting network access to the cardholder data environment (CDE), which aligns with the requirement to restrict inbound and outbound traffic to only that which is necessary.\n",
      "Requirement 9.3.2.c\n",
      "\n",
      "The network diagram demonstrates the use of secure network segments in Azure and virtual private networks (VPNs), which aligns with requirements for secure access and visitor management within the Cardholder Data Environment (CDE).\n",
      "Requirement 10.6.1: System clocks and time are synchronized using time-synchronization technology. \n",
      "\n",
      "This is addressed by the presence of NTP (Network Time Protocol) servers in the network diagram, ensuring synchronized time settings across all systems.\n",
      "Requirement 1.2.3: Use of Virtual Network (VNET) for segmentation.\n",
      "\n",
      "Requirement 11.2.1: Regular monitoring of authorized and unauthorized wireless access points using network segmentation.\n",
      "Requirement 11.5.1: The network diagram indicates traffic is monitored at various points within the CDE using TLS, which aligns with the requirement to monitor all traffic at the perimeter and critical points in the Cardholder Data Environment (CDE) for intrusion-detection and/or prevention purposes.\n",
      "Requirement 1.1.2\n",
      "\n",
      "Explanation: This requirement involves creating and maintaining a network diagram that identifies all connections between the cardholder data environment (CDE) and other networks, including any wireless networks. The provided network diagram illustrates these connections, supporting compliance with this requirement.\n",
      "Requirement 1.2.3\n",
      "\n",
      "Explanation: The diagram appears to include network segmentation and firewalls to restrict inbound and outbound traffic to secure environments, aligning with the requirement to install and configure a firewall at each Internet connection and between any demilitarized zone (DMZ) and the internal network zone.\n",
      "Requirement 12.8.1\n",
      "\n",
      "The diagram displays details about network segmentation with virtual networks (VNETs), maintaining a list of third-party service providers using different environments for various services.\n",
      "- **Requirement A2.1.1**: TLS v1.2 is used, confirming the entity's devices are not susceptible to any known SSL/early TLS exploits.\n",
      "- **Requirement A1.1.4**: The diagram suggests logical separation, which may relate to the requirement for verifying logical separation controls through penetration testing.\n",
      "- **Requirement A1.2.1**: The use of audit log capability, as systems appear segmented and designated (e.g., Card Data Environment), aligns with secure logging practices.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    pdf_path = \"PCI-DSS-ROC-Template.pdf\"       # Path to your PCI-DSS ROC PDF\n",
    "    image_path = \"Connfido Network Diagram.png\"  # Client screenshot image path\n",
    "\n",
    "    print(\"Processing PDF and loading cached sections...\")\n",
    "    processed_sections = load_or_process_pdf(pdf_path)\n",
    "    if not processed_sections:\n",
    "        print(\"No processed sections found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"Found sections:\")\n",
    "    for title in processed_sections:\n",
    "        print(f\"--- {title} ---\")\n",
    "\n",
    "    print(\"Extracting OCR text from image...\")\n",
    "    image_query = ocr_image(image_path)\n",
    "\n",
    "    mapped_controls = []\n",
    "    # Loop over each section and its sub-chunks\n",
    "    for title, chunk_list in processed_sections.items():\n",
    "        for chunk in chunk_list:\n",
    "            if check_chunk_relevance(chunk, image_query):\n",
    "                print(f\"Chunk from section '{title}' is relevant. Mapping control...\")\n",
    "                mapping = map_chunk_to_control(chunk, image_path, image_query)\n",
    "                if mapping:\n",
    "                    mapped_controls.append(mapping)\n",
    "\n",
    "    if not mapped_controls:\n",
    "        print(\"No mapped controls found for the given image. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Deduplicate the mapping outputs (preserving order)\n",
    "    unique_mapped_controls = list(dict.fromkeys(mapped_controls))\n",
    "    aggregated_mapping = \"\\n\".join(unique_mapped_controls)\n",
    "    print(\"Aggregated Mapped Controls:\")\n",
    "    print(aggregated_mapping)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b458e232-c2db-447e-9bcb-d4dcece6f89e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48cd05a-02a8-450c-9070-582e8ff19893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "037afbdc-5d3f-4ece-b6f5-aa0970dd087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": f\"\"\"\n",
    "                    PCI-DSS Section: {chunk['title']}\n",
    "                    Document Text: {chunk['text'][:20000]}\n",
    "                    Image Context: {ocr_text}\n",
    "\n",
    "                    Task:\n",
    "                    1. Does this image provide evidence for a specific control(s) and/or \n",
    "                    requirements in this section?\n",
    "                    2. Identify the EXACT control references from text.\n",
    "                    3. Match image features to control requirements.\n",
    "                    \n",
    "                    Identify if the image shows implementation of ANY control from this section.\n",
    "                    Respond ONLY with matching control/requirement number, name, and description (e.g., '7.1 Processes and mechanisms for restricting access to system components and cardholder data by business need to know are defined and understood.') or 'None'\"\"\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": image_data}}\n",
    " \n",
    "\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in PCI-DSS compliance. \n",
    "    You are given a section extracted from the PCI-DSS Report on Compliance Template containing the controls and requirements.\n",
    "    A client has provided a screenshot showing details of their network and security configuration.\n",
    "    Analyze the image and identify which specific control requirement is being addressed.\n",
    "    Provide the control requirement code along with a detailed explanation of \n",
    "    how the information in the given image satisfies that requirement.\n",
    "    Please be as specific as possible in your mapping.\n",
    "    \"\"\"\n",
    "    \n",
    "    detailed_response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt},\n",
    "            {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": f\"\"\"\n",
    "                Potential Controls: {', '.join(controls)}\n",
    "                Full OCR Text: {ocr_text}\n",
    "                \n",
    "                Generate final mapping report with:\n",
    "                1. Controls/requirements from the PCI-DSS standard\n",
    "                2. Implementation evidence from the image\n",
    "                3. Relevant requirement text from document\"\"\"},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_data}}\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a53eb1b8-1330-4051-a350-c17a10cdbfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "def main():\n",
    "    # First run - processes and caches PDF\n",
    "    get_pdf_chunks()  \n",
    "    \n",
    "    # Process multiple images\n",
    "    for img in [\"card_decryption_flow.jpg\"]:\n",
    "        print(f\"\\nProcessing {img}...\")\n",
    "        print(process_image(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149abc4-ad62-4e87-99ea-48af8cb7a8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b015dd8c-5a09-4419-a89d-8bdf2a1bf12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze section of the document to map given image\n",
    "def analyze_section(section: dict, image_data_url: str, ocr_text: str) -> dict:\n",
    "    \"\"\"Analyze one document section with image context\"\"\"\n",
    "    instruct_prompt = f\"\"\"\n",
    "    PCI-DSS Document Section Analysis\n",
    "    Section Title: {section['title']}\n",
    "    Section Content: {section['content'][:2500]}\n",
    "    \n",
    "    OCR Context from Image: {ocr_text}\n",
    "    \n",
    "    Task:\n",
    "    1. Does this image provide evidence for this specific control?\n",
    "    2. Identify EXACT control references from text\n",
    "    3. Match image features to control requirements\n",
    "    \n",
    "    Respond STRICTLY in format:\n",
    "    Relevant: [Yes/No]\n",
    "    Control: [exact control text from document]\n",
    "    Match Confidence: [High/Medium/Low]\n",
    "    Evidence: [specific matching details from image]\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in PCI-DSS compliance. \n",
    "    You are given a section extracted from the PCI-DSS Report on Compliance Template containing the controls and requirements.\n",
    "    A client has provided a screenshot showing details of their network and security configuration.\n",
    "    Analyze the image and identify which specific control requirement is being addressed.\n",
    "    Provide the control requirement code along with a detailed explanation of \n",
    "    how the information in the given image satisfies that requirement.\n",
    "    Please be as specific as possible in your mapping.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": instruct_prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": image_data_url}}\n",
    "                ]}\n",
    "            ],\n",
    "            max_tokens=400\n",
    "        )\n",
    "        return parse_response(response.choices[0].message.content, section)\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing section: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3cb7a0e-d0ff-4f46-8f96-fd806a1d3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(response: str, section: dict) -> dict:\n",
    "    lines = response.split(\"\\n\")\n",
    "    result = {\n",
    "        \"relevant\": False,\n",
    "        \"control\": \"\",\n",
    "        \"confidence\": \"\",\n",
    "        \"evidence\": \"\",\n",
    "        \"section_title\": section[\"title\"],\n",
    "        \"section_content\": section[\"content\"][:1000] + \"...\" \n",
    "    }\n",
    "    \n",
    "    for line in lines:\n",
    "        if \"Relevant: Yes\" in line:\n",
    "            result[\"relevant\"] = True\n",
    "        elif \"Control:\" in line:\n",
    "            result[\"control\"] = line.split(\"Control:\")[-1].strip()\n",
    "        elif \"Match Confidence:\" in line:\n",
    "            result[\"confidence\"] = line.split(\"Match Confidence:\")[-1].strip()\n",
    "        elif \"Evidence:\" in line:\n",
    "            result[\"evidence\"] = line.split(\"Evidence:\")[-1].strip()\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f17a2f7f-7230-434e-9919-0ee9140503fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_results(findings: list, image_data_url: str) -> str:\n",
    "    \"\"\"Final validation with all positive matches\"\"\"\n",
    "    validation_prompt = \"\"\"\n",
    "    Cross-Validate PCI-DSS Matches\n",
    "    \n",
    "    Positive Matches:\n",
    "    \"\"\" + \"\\n\".join(\n",
    "        f\"{i+1}. {f['control']} (Confidence: {f['confidence']})\"\n",
    "        for i, f in enumerate(findings)\n",
    "    ) + \"\"\"\n",
    "    \n",
    "    Task:\n",
    "    1. Eliminate false positives\n",
    "    2. Rank matches by relevance\n",
    "    3. Combine supporting evidence\n",
    "    4. Cite exact requirement text\n",
    "    \n",
    "    Final report format:\n",
    "    ## PCI-DSS Compliance Mapping\n",
    "    **Primary Control**: [control code] - [description]\n",
    "    - Image Evidence: [specific features]\n",
    "    - Document Reference: [exact text snippet]\n",
    "    - Compliance Status: [Met/Partial/Not Met]\n",
    "    \n",
    "    [Repeat for secondary controls]\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a senior PCI-DSS auditor.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": validation_prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_data_url}}\n",
    "            ]}\n",
    "        ],\n",
    "        max_tokens=600\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202376ce-da48-4a39-812d-fcfc9b58f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    pdf_path = \"PCI-DSS-ROC-Template.pdf\"\n",
    "    image_path = \"Connfido Network Diagram.png\"\n",
    "    \n",
    "    print(\"Processing document structure...\")\n",
    "    sections = extract_sections_from_pdf(pdf_path)\n",
    "    print(f\"Identified {len(sections)} logical sections\")\n",
    "    \n",
    "    ocr_text = ocr_image(image_path)\n",
    "    image_data_url = image_to_data_url(image_path)\n",
    "    \n",
    "    findings = []\n",
    "    for idx, section in enumerate(sections):\n",
    "        print(f\"Analyzing section {idx+1}/{len(sections)}: {section['title'][:50]}...\")\n",
    "        result = analyze_section(section, image_data_url, ocr_text)\n",
    "        if result and result[\"relevant\"]:\n",
    "            findings.append(result)\n",
    "    \n",
    "    if findings:\n",
    "        print(\"\\nCross-validating results...\")\n",
    "        final_report = cross_validate_results(findings, image_data_url)\n",
    "        print(\"\\nFINAL COMPLIANCE MAPPING:\")\n",
    "        print(final_report)\n",
    "    else:\n",
    "        print(\"No PCI-DSS controls matched to the image content\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45f84ac8-d871-41f6-bfa3-08d26544e9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document structure...\n",
      "Identified 1 logical sections\n",
      "Analyzing section 1/1: Document Start...\n",
      "\n",
      "Cross-validating results...\n",
      "\n",
      "FINAL COMPLIANCE MAPPING:\n",
      "## PCI-DSS Compliance Mapping\n",
      "\n",
      "**Primary Control**: 4.1 - Use strong cryptography and security protocols to protect sensitive cardholder data during transmission over open, public networks.\n",
      "\n",
      "- **Image Evidence**: The image shows network diagrams, which seem to include components indicating encryption protocols, such as VPNs or SSL/TLS labels. The lines between systems might denote encrypted communication paths.\n",
      "\n",
      "- **Document Reference**: \"Use strong cryptography and security protocols to protect sensitive cardholder data during transmission over open, public networks.\"\n",
      "\n",
      "- **Compliance Status**: Met\n",
      "\n",
      "**Secondary Control**: (If applicable, repeat the format above for additional controls identified in the documentation or network diagram.)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f5b361-3a25-4e20-969b-a80727e6f141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "661d4aac-af5e-4a34-a0a0-844a37286db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF and loading cached sections...\n",
      "Section 'General' is very large (150575 tokens); splitting further.\n",
      "Processed PDF and saved cache.\n",
      "Found sections:\n",
      "--- General ---\n",
      "--- General ---\n",
      "--- General ---\n",
      "--- General ---\n",
      "--- General ---\n",
      "--- General ---\n",
      "--- General ---\n",
      "--- General ---\n",
      "--- General ---\n",
      "--- General ---\n",
      "--- General ---\n",
      "--- General ---\n",
      "--- General ---\n",
      "--- General ---\n",
      "--- General ---\n",
      "--- General ---\n",
      "Extracting OCR text from image...\n",
      "Chunk from section 'General' is relevant. Mapping control...\n",
      "Raw mapping output: ```json\n",
      "{\n",
      "    \"control_code\": \"Requirement 1.1.3\",\n",
      "    \"description\": \"Network diagrams that show all connections to cardholder data, including any wireless networks.\",\n",
      "    \"explanation\": \"The screenshot provides a detailed network diagram showing connections, which is necessary for understanding and securing the cardholder data environment.\"\n",
      "}\n",
      "```\n",
      "Mapping error for chunk: Expecting value: line 1 column 1 (char 0)\n",
      "Chunk from section 'General' is relevant. Mapping control...\n",
      "Raw mapping output: ```json\n",
      "{\n",
      "    \"control_code\": \"Requirement 1.2.3\",\n",
      "    \"description\": \"An accurate network diagram(s) is maintained that shows all connections between the CDE and other networks, including any wireless networks.\",\n",
      "    \"explanation\": \"The screenshot provides a detailed network diagram showing connections between various network segments, including the Card Data Environment (CDE), which satisfies the requirement for maintaining an accurate network diagram.\"\n",
      "}\n",
      "```\n",
      "Mapping error for chunk: Expecting value: line 1 column 1 (char 0)\n",
      "Chunk from section 'General' is relevant. Mapping control...\n",
      "Raw mapping output: ```json\n",
      "{\n",
      "    \"control_code\": \"Requirement 1.3.3\",\n",
      "    \"description\": \"NSCs are installed between all wireless networks and the CDE, regardless of whether the wireless network is a CDE, such that: • All wireless traffic from wireless networks into the CDE is denied by default. • Only wireless traffic with an authorized business purpose is allowed into the CDE.\",\n",
      "    \"explanation\": \"The network diagram shows NSCs implemented between wireless networks and the CDE, ensuring traffic is controlled and only authorized traffic is allowed, which aligns with the requirement.\"\n",
      "}\n",
      "```\n",
      "Mapping error for chunk: Expecting value: line 1 column 1 (char 0)\n",
      "Chunk from section 'General' is relevant. Mapping control...\n",
      "Raw mapping output: ```json\n",
      "{}\n",
      "```\n",
      "Mapping error for chunk: Expecting value: line 1 column 1 (char 0)\n",
      "Chunk from section 'General' is relevant. Mapping control...\n",
      "Raw mapping output: ```json\n",
      "{\n",
      "    \"control_code\": \"Requirement 4.2.1\",\n",
      "    \"description\": \"Strong cryptography and security protocols are implemented as follows to safeguard PAN during transmission over open, public networks.\",\n",
      "    \"explanation\": \"The network diagram shows the use of TLS v1.2 or above for secure transmission, which aligns with the requirement to use strong cryptography for protecting PAN during transmission over open, public networks.\"\n",
      "}\n",
      "```\n",
      "Mapping error for chunk: Expecting value: line 1 column 1 (char 0)\n",
      "Chunk from section 'General' is relevant. Mapping control...\n",
      "Raw mapping output: ```json\n",
      "{\n",
      "    \"control_code\": \"Requirement 6.5.3\",\n",
      "    \"description\": \"Pre-production environments are separated from production environments and the separation is enforced with access controls.\",\n",
      "    \"explanation\": \"The network diagram shows distinct separation between different environments, indicating compliance with the requirement to separate pre-production and production environments.\"\n",
      "}\n",
      "```\n",
      "Mapping error for chunk: Expecting value: line 1 column 1 (char 0)\n",
      "Chunk from section 'General' is relevant. Mapping control...\n",
      "Raw mapping output: ```json\n",
      "{}\n",
      "```\n",
      "Mapping error for chunk: Expecting value: line 1 column 1 (char 0)\n",
      "Chunk from section 'General' is relevant. Mapping control...\n",
      "Raw mapping output: ```json\n",
      "{\n",
      "    \"control_code\": \"Requirement 9.2.1\",\n",
      "    \"description\": \"Appropriate facility entry controls are in place to restrict physical access to systems in the CDE.\",\n",
      "    \"explanation\": \"The network diagram shows the segmentation and access controls in place for the cardholder data environment (CDE), indicating restricted access to sensitive areas.\"\n",
      "}\n",
      "```\n",
      "Mapping error for chunk: Expecting value: line 1 column 1 (char 0)\n",
      "Chunk from section 'General' is relevant. Mapping control...\n",
      "Mapping error for chunk: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "Relevance check error: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n",
      "No mapped controls found for the given image. Exiting.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from mimetypes import guess_type\n",
    "from PIL import Image\n",
    "import fitz\n",
    "import pytesseract\n",
    "import tiktoken\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Configuration\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"  # Set your API key\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "CHUNKS_CACHE_FILE = \"pci_processed_chunks.json\"\n",
    "TOKEN_THRESHOLD = 10000\n",
    "MIN_CHUNK_TOKENS = 300  # Minimum tokens per chunk before merging\n",
    "\n",
    "# --------------------------\n",
    "# PDF Processing Utilities\n",
    "# --------------------------\n",
    "\n",
    "def partition_pdf_by_title(pdf_path):\n",
    "    \"\"\"\n",
    "    Partition the PDF into ordered sections with titles using metadata.\n",
    "    Returns a list of dicts: [{'title': <str>, 'content': <str>}, ...]\n",
    "    \"\"\"\n",
    "    elements = partition_pdf(filename=pdf_path)\n",
    "    sections = []\n",
    "    current_title = \"General\"\n",
    "    current_content = []\n",
    "    \n",
    "    for element in elements:\n",
    "        text = element.text.strip()\n",
    "        category = getattr(element.metadata, \"category\", \"\") if element.metadata else \"\"\n",
    "        \n",
    "        if category in [\"Title\", \"Header\"]:\n",
    "            if current_content:\n",
    "                sections.append({\n",
    "                    \"title\": current_title,\n",
    "                    \"content\": \"\\n\".join(current_content)\n",
    "                })\n",
    "                current_content = []\n",
    "            current_title = text\n",
    "        else:\n",
    "            current_content.append(text)\n",
    "    \n",
    "    if current_content:\n",
    "        sections.append({\n",
    "            \"title\": current_title,\n",
    "            \"content\": \"\\n\".join(current_content)\n",
    "        })\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"Count tokens using tiktoken.\"\"\"\n",
    "    return len(tiktoken.get_encoding(\"cl100k_base\").encode(text))\n",
    "\n",
    "\n",
    "def split_text_into_chunks(text: str, max_tokens: int = TOKEN_THRESHOLD, overlap: int = 100) -> list:\n",
    "    \"\"\"Split text into overlapping chunks based on token count.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = start + max_tokens\n",
    "        chunk = encoding.decode(tokens[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap  # maintain overlap for continuity\n",
    "    return chunks\n",
    "\n",
    "def merge_small_chunks(chunks: list, min_tokens: int = MIN_CHUNK_TOKENS) -> list:\n",
    "    \"\"\"Merge adjacent chunks if a chunk is very small.\"\"\"\n",
    "    merged = []\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    i = 0\n",
    "    while i < len(chunks):\n",
    "        current = chunks[i]\n",
    "        current_tokens = len(encoding.encode(current))\n",
    "        if current_tokens < min_tokens and i + 1 < len(chunks):\n",
    "            merged_chunk = current + \"\\n\" + chunks[i+1]\n",
    "            merged.append(merged_chunk)\n",
    "            i += 2\n",
    "        else:\n",
    "            merged.append(current)\n",
    "            i += 1\n",
    "    return merged\n",
    "\n",
    "def process_sections(pdf_path):\n",
    "    \"\"\"\n",
    "    Partition the PDF by title and, for each section that exceeds TOKEN_THRESHOLD,\n",
    "    split it into sub-chunks and merge small chunks.\n",
    "    Returns a list of dicts: [{'title': <str>, 'text': <str>}, ...]\n",
    "    \"\"\"\n",
    "    raw_sections = partition_pdf_by_title(pdf_path)\n",
    "    all_chunks = []\n",
    "    for section in raw_sections:\n",
    "        full_text = f\"{section['title']}\\n{section['content']}\"\n",
    "        tokens = count_tokens(full_text)\n",
    "        if tokens <= TOKEN_THRESHOLD:\n",
    "            all_chunks.append({\n",
    "                \"title\": section['title'],\n",
    "                \"text\": full_text,\n",
    "                \"tokens\": tokens\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Section '{section['title']}' is very large ({tokens} tokens); splitting further.\")\n",
    "            sub_chunks = split_text_into_chunks(full_text, max_tokens=TOKEN_THRESHOLD, overlap=100)\n",
    "            merged_chunks = merge_small_chunks(sub_chunks, min_tokens=MIN_CHUNK_TOKENS)\n",
    "            for chunk in merged_chunks:\n",
    "                all_chunks.append({\n",
    "                    \"title\": section['title'],\n",
    "                    \"text\": chunk,\n",
    "                    \"tokens\": count_tokens(chunk)\n",
    "                })\n",
    "    return all_chunks\n",
    "\n",
    "\n",
    "def load_or_process_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Load cached processed PDF sections if available; otherwise, process the PDF and cache the result.\n",
    "    Expected cache format: list of dicts with keys \"title\" and \"text\".\n",
    "    \"\"\"\n",
    "    if os.path.exists(CHUNKS_CACHE_FILE):\n",
    "        with open(CHUNKS_CACHE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            chunks = json.load(f)\n",
    "        print(\"Loaded cached processed PDF sections.\")\n",
    "    else:\n",
    "        chunks = process_sections(pdf_path)\n",
    "        with open(CHUNKS_CACHE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(chunks, f, ensure_ascii=False, indent=2)\n",
    "        print(\"Processed PDF and saved cache.\")\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Image Processing\n",
    "# --------------------------\n",
    "\n",
    "def ocr_image(image_path):\n",
    "    \"\"\"Extract text from an image using pytesseract.\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    return pytesseract.image_to_string(image)\n",
    "\n",
    "def image_to_data_url(image_path: str) -> str:\n",
    "    \"\"\"Convert an image file to a base64-encoded data URL.\"\"\"\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'image/png'\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        encoded = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    return f\"data:{mime_type};base64,{encoded}\"\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# API Interaction Handlers\n",
    "# --------------------------\n",
    "\n",
    "def check_chunk_relevance(chunk_text: str, image_ocr: str) -> bool:\n",
    "    \"\"\"Determine if chunk is relevant using GPT-4 with batch optimization.\"\"\"\n",
    "    \n",
    "    system_message = f\"\"\"\n",
    "    You are an expert in PCI-DSS compliance. \n",
    "    Analyze if the document section contains PCI-DSS controls relevant to the information in the given image.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Document chunk:\n",
    "    \\\"\\\"\\\"{chunk_text}\\\"\\\"\\\"\n",
    "    \n",
    "    Client screenshot text:\n",
    "    \\\"\\\"\\\"{image_ocr}\\\"\\\"\\\"\n",
    "    \n",
    "    Is this chunk relevant for mapping the client's network/security information to a PCI-DSS control? \n",
    "    Answer only \"Yes\" or \"No\".\n",
    "    \"\"\"\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message}, \n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            max_tokens=10,\n",
    "            temperature=0\n",
    "        )\n",
    "        answer = response.choices[0].message.content.strip().lower()\n",
    "        return answer.startswith(\"yes\")\n",
    "    except Exception as e:\n",
    "        print(f\"Relevance check error: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def map_chunk_to_control(chunk_text: str, image_ocr: str, image_path: str) -> dict:\n",
    "    \"\"\"Get structured control mappings from GPT-4 Vision.\"\"\"\n",
    "\n",
    "    system_message = \"You are an expert in PCI-DSS compliance.\"\n",
    "    prompt = f\"\"\"\n",
    "    Document chunk:\n",
    "    \\\"\\\"\\\"{chunk_text}\\\"\\\"\\\"\n",
    "    \n",
    "    Client screenshot text:\n",
    "    \\\"\\\"\\\"{image_ocr}\\\"\\\"\\\"\n",
    "    \n",
    "    Based solely on the above, identify which specific control requirement the screenshot addresses.\n",
    "    Return your answer as a single-line JSON object with exactly these keys:\n",
    "      \"control_code\": string (e.g., \"Requirement 1.1.2a\"),\n",
    "      \"description\": string (an excerpt from the document describing the requirement),\n",
    "      \"explanation\": string (a brief explanation of why the image satisfies this requirement).\n",
    "    If no control applies, return empty JSON object.\n",
    "    Output only the JSON with no extra text.\n",
    "    \"\"\"\n",
    "    image_data_url = image_to_data_url(image_path)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": image_data_url}}\n",
    "        ]}\n",
    "    ]\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            max_tokens=200,\n",
    "            temperature=0.2\n",
    "        )\n",
    "        output = response.choices[0].message.content.strip()\n",
    "        print(\"Raw mapping output:\", output)  # Debug print\n",
    "        if not output:\n",
    "            return {}\n",
    "        mapping = json.loads(output)\n",
    "        if mapping.get(\"control_code\"):\n",
    "            return mapping\n",
    "        else:\n",
    "            return {}\n",
    "    except Exception as e:\n",
    "        print(f\"Mapping error for chunk: {e}\")\n",
    "        return {}\n",
    "\n",
    "# --------------------------\n",
    "# Aggregation and Deduplication\n",
    "# --------------------------\n",
    "\n",
    "def aggregate_mappings(mappings: list) -> dict:\n",
    "    \"\"\"\n",
    "    Aggregate a list of mapping dictionaries into a deduplicated dict keyed by control code.\n",
    "    Merge explanations for duplicate control codes.\n",
    "    \"\"\"\n",
    "    aggregated = {}\n",
    "    for mapping in mappings:\n",
    "        code = mapping.get(\"control_code\")\n",
    "        if not code:\n",
    "            continue\n",
    "        if code in aggregated:\n",
    "            existing_expl = aggregated[code][\"explanation\"]\n",
    "            new_expl = mapping.get(\"explanation\", \"\")\n",
    "            if new_expl and new_expl not in existing_expl:\n",
    "                aggregated[code][\"explanation\"] += \" \" + new_expl\n",
    "        else:\n",
    "            aggregated[code] = {\n",
    "                \"description\": mapping.get(\"description\", \"\"),\n",
    "                \"explanation\": mapping.get(\"explanation\", \"\")\n",
    "            }\n",
    "    return aggregated\n",
    "\n",
    "# --------------------------\n",
    "# Main Workflow\n",
    "# --------------------------\n",
    "\n",
    "def main():\n",
    "    pdf_path = \"PCI-DSS-ROC-Template.pdf\"       # Path to your PCI-DSS ROC PDF\n",
    "    image_path = \"Connfido Network Diagram.png\"  # Client screenshot image path\n",
    "\n",
    "    print(\"Processing PDF and loading cached sections...\")\n",
    "    chunks = load_or_process_pdf(pdf_path)\n",
    "    if not chunks:\n",
    "        print(\"No processed sections found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"Found sections:\")\n",
    "    for item in chunks:\n",
    "        print(f\"--- {item['title']} ---\")\n",
    "\n",
    "    print(\"Extracting OCR text from image...\")\n",
    "    image_ocr = ocr_image(image_path)\n",
    "\n",
    "    mapping_outputs = []\n",
    "    # Loop over each chunk in the processed sections\n",
    "    for item in chunks:\n",
    "        text = item['text']\n",
    "        if not text.strip():\n",
    "            continue\n",
    "        if check_chunk_relevance(text, image_ocr):\n",
    "            print(f\"Chunk from section '{item['title']}' is relevant. Mapping control...\")\n",
    "            mapping = map_chunk_to_control(text, image_ocr, image_path)\n",
    "            if mapping and mapping.get(\"control_code\"):\n",
    "                mapping_outputs.append(mapping)\n",
    "\n",
    "    if not mapping_outputs:\n",
    "        print(\"No mapped controls found for the given image. Exiting.\")\n",
    "        return\n",
    "\n",
    "    aggregated = aggregate_mappings(mapping_outputs)\n",
    "    print(\"Final Aggregated Mapped Controls:\")\n",
    "    for code, details in aggregated.items():\n",
    "        print(f\"\\nControl: {code}\")\n",
    "        print(f\"Description: {details['description']}\")\n",
    "        print(f\"Explanation: {details['explanation']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7fc1a-157b-41e2-938e-7f2b9b6139a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lang-env]",
   "language": "python",
   "name": "conda-env-lang-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
