{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44c7d2-5e1d-437c-9f52-645f0404b874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF and loading cached sections...\n",
      "Loaded cached processed PDF sections.\n",
      "Found sections:\n",
      "--- General ---\n",
      "--- PCI DSS 4.0 ---\n",
      "--- DO: ---\n",
      "--- DON’T: ---\n",
      "--- DSS. ---\n",
      "--- OR • ---\n",
      "--- CDE. ---\n",
      "--- IDS/IPS. ---\n",
      "--- FIM. ---\n",
      "--- OR ---\n",
      "Extracting OCR text from image...\n",
      "Chunk from section 'General' is relevant. Mapping control...\n",
      "Chunk from section 'PCI DSS 4.0' is relevant. Mapping control...\n",
      "Chunk from section 'DO:' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'OR •' is relevant. Mapping control...\n",
      "Chunk from section 'OR •' is relevant. Mapping control...\n",
      "Chunk from section 'OR •' is relevant. Mapping control...\n",
      "Chunk from section 'CDE.' is relevant. Mapping control...\n",
      "Chunk from section 'CDE.' is relevant. Mapping control...\n",
      "Chunk from section 'IDS/IPS.' is relevant. Mapping control...\n",
      "Chunk from section 'IDS/IPS.' is relevant. Mapping control...\n",
      "Chunk from section 'FIM.' is relevant. Mapping control...\n",
      "Chunk from section 'OR' is relevant. Mapping control...\n",
      "Chunk from section 'OR' is relevant. Mapping control...\n",
      "Chunk from section 'OR' is relevant. Mapping control...\n",
      "Aggregated Mapped Controls:\n",
      "Requirement 1.1.3\n",
      "\n",
      "Ensures there is a network diagram that identifies all connections between the cardholder data environment and other networks, including any wireless networks.\n",
      "Requirement 4: Protect Cardholder Data with Strong Cryptography During Transmission Over Open, Public Networks.\n",
      "\n",
      "Explanation: The network diagram shows data transmission over port 443 using TLS v1.2 or above, which aligns with the requirement to protect cardholder data with strong cryptography during transmission over open, public networks.\n",
      "Requirement 1.1.3\n",
      "\n",
      "Document and maintain a network diagram that shows all connections to cardholder data, including any wireless networks.\n",
      "Requirement 1.1.2: The network diagram provided in the screenshot shows a detailed representation of the network, including cardholder data environments and connections with other networks.\n",
      "Requirement 1.2.3\n",
      "\n",
      "The diagram includes details about network configurations, which address the creation and maintenance of accurate network diagrams showing all connections between the Cardholder Data Environment (CDE) and other networks.\n",
      "- **Requirement 2.2.2**: Managing vendor default accounts - the configuration must ensure that these defaults are changed or removed.\n",
      "- **Requirement 2.2.7**: Encryption for all non-console administrative access, as indicated by the use of TLS v1.2 or above on Port 443/TCP.\n",
      "\n",
      "Requirement 3.4.1 - This relates to masking the display of PANs as indicated by the network's reference to protective measures such as using TLS v1.2, which aligns with secure transmission and storage protocols for PAN data.\n",
      "Requirement 4.2.1\n",
      "\n",
      "Strong cryptography is used to protect PAN during transmission over open, public networks using TLS v1.2 or above.\n",
      "Requirement 1.1.1\n",
      "\n",
      "Explanation: The diagram depicts a network segmentation with details regarding the use of firewalls and VNETs. This aligns with Requirement 1.1.1, which involves establishing a formal process for network management, including documentation of network diagrams and connectivity.\n",
      "Requirement 6.4.1\n",
      "\n",
      "Explanation: The diagram shows network segmentation and controls such as Virtual Networks (VNETs) and Network Security Groups (NSGs), which are relevant to ensuring that controls detect and prevent web-based attacks in front of public-facing web applications.\n",
      "Requirement 8.2.1\n",
      "\n",
      "Explanation: The network diagram shows end-user connections and system component access, implying user identification and authentication processes are implemented, addressing the need for unique user IDs before access is permitted.\n",
      "Requirement 8.4.1\n",
      "\n",
      "The network diagram shows the use of Azure infrastructure and TLS v1.2 for secure connections, indicating multi-factor authentication (MFA) implementation to secure access into the cardholder data environment (CDE) for personnel with administrative access.\n",
      "Requirement 1.1.1\n",
      "\n",
      "Network diagram shows the segmentation of systems with cardholder data (CDE) and other networks.\n",
      "Requirement 10.6.1: System clocks and time are synchronized using time-synchronization technology. The diagram includes network details potentially indicating synchronized environments.\n",
      "\n",
      "Requirement 10.2.1.1: Audit logs capture all individual user access to cardholder data. The presence of secure connections and specified environments suggests audit logging of user access.\n",
      "Requirement 1.1.4: Documented current network diagram showing all connections to cardholder data. The diagram outlines connections within and outside the network, depicting cardholder data flow and storage.\n",
      "Requirement 11.5.1\n",
      "\n",
      "Explanation: The network diagram shows traffic monitoring points such as around \"CARD DATA ENVIRONMENT\" which aligns with the requirement to monitor all traffic at critical points in the Cardholder Data Environment (CDE).\n",
      "Requirement 1.1.3\n",
      "\n",
      "The provided network diagram addresses the requirement for establishing a current network diagram that identifies all connections and boundaries for data flow of cardholder data within the environment.\n",
      "Requirement 12.1.1\n",
      "\n",
      "The diagram shows a structured network with distinct VNETs and cardholder data environments, indicating the establishment of an information security policy that governs and provides direction for protection of the entity's information assets.\n",
      "Requirement 12.10.5\n",
      "\n",
      "The network diagram illustrates monitoring and responding to alerts from security monitoring systems, which aligns with the requirement to include such practices in the security incident response plan.\n",
      "Requirement A2.1.1\n",
      "\n",
      "The use of TLS v1.2 or above for secure communications indicates compliance with requirements for secure transmission channels, confirming that devices are not susceptible to known exploits for SSL/early TLS.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from mimetypes import guess_type\n",
    "from PIL import Image\n",
    "import fitz\n",
    "import pytesseract\n",
    "import tiktoken\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Set your OpenAI API key \n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# File names for caching\n",
    "CHUNKS_CACHE_FILE = \"pci_processed_chunks.json\"\n",
    "TOKEN_THRESHOLD = 10000\n",
    "\n",
    "# --------------------------\n",
    "# PDF Partitioning and Caching\n",
    "# --------------------------\n",
    "\n",
    "def partition_pdf_by_title(pdf_path):\n",
    "    \"\"\"\n",
    "    Use unstructured to partition the PDF into sections based on titles/headers.\n",
    "    Returns a dict mapping section titles to their full text.\n",
    "    \"\"\"\n",
    "    elements = partition_pdf(filename=pdf_path)\n",
    "    sections = {}\n",
    "    current_title = \"General\"\n",
    "    sections[current_title] = \"\"\n",
    "    for element in elements:\n",
    "        text = element.text.strip()\n",
    "        # Use getattr to safely access metadata (which is not a dict)\n",
    "        category = getattr(element.metadata, \"category\", \"\") if element.metadata else \"\"\n",
    "        if category in [\"Title\", \"Header\"] or (text and text.isupper() and len(text.split()) < 10):\n",
    "            current_title = text\n",
    "            if current_title not in sections:\n",
    "                sections[current_title] = \"\"\n",
    "        else:\n",
    "            sections[current_title] += \"\\n\" + text\n",
    "    return sections\n",
    "\n",
    "def count_tokens(text: str, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"Count tokens using tiktoken for a given model.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def split_text_into_chunks(text: str, max_tokens: int = TOKEN_THRESHOLD, overlap: int = 100) -> list:\n",
    "    \"\"\"\n",
    "    Split a long text into overlapping chunks based on token count.\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = start + max_tokens\n",
    "        chunk = encoding.decode(tokens[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap  # maintain overlap for context continuity\n",
    "    return chunks\n",
    "\n",
    "def process_pdf_sections(pdf_path):\n",
    "    \"\"\"\n",
    "    Partition the PDF by title and, for each section that exceeds TOKEN_THRESHOLD,\n",
    "    further split it into sub-chunks.\n",
    "    Returns a dictionary mapping section titles to lists of text chunks.\n",
    "    \"\"\"\n",
    "    raw_sections = partition_pdf_by_title(pdf_path)\n",
    "    processed_sections = {}\n",
    "    for title, content in raw_sections.items():\n",
    "        full_section = f\"{title}\\n{content}\"\n",
    "        tokens = count_tokens(full_section)\n",
    "        if tokens > TOKEN_THRESHOLD:\n",
    "            print(f\"Section '{title}' is very large ({tokens} tokens); splitting further.\")\n",
    "            sub_chunks = split_text_into_chunks(full_section, max_tokens=TOKEN_THRESHOLD, overlap=100)\n",
    "            processed_sections[title] = sub_chunks\n",
    "        else:\n",
    "            processed_sections[title] = [full_section]\n",
    "    return processed_sections\n",
    "\n",
    "def load_or_process_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Load cached processed PDF sections if available; otherwise, process the PDF and cache the result.\n",
    "    \"\"\"\n",
    "    if os.path.exists(CHUNKS_CACHE_FILE):\n",
    "        with open(CHUNKS_CACHE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            processed_sections = json.load(f)\n",
    "        print(\"Loaded cached processed PDF sections.\")\n",
    "    else:\n",
    "        processed_sections = process_pdf_sections(pdf_path)\n",
    "        with open(CHUNKS_CACHE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(processed_sections, f, ensure_ascii=False, indent=2)\n",
    "        print(\"Processed PDF and saved cache.\")\n",
    "    return processed_sections\n",
    "\n",
    "# --------------------------\n",
    "# Image and OCR Utilities\n",
    "# --------------------------\n",
    "\n",
    "def ocr_image(image_path):\n",
    "    \"\"\"Extract text from an image using pytesseract.\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    return pytesseract.image_to_string(image)\n",
    "\n",
    "def image_to_data_url(image_path: str) -> str:\n",
    "    \"\"\"Convert an image file to a base64-encoded data URL.\"\"\"\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'application/octet-stream'\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        encoded = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    return f\"data:{mime_type};base64,{encoded}\"\n",
    "\n",
    "# --------------------------\n",
    "# Token Counting Utility\n",
    "# --------------------------\n",
    "\n",
    "def count_tokens(text: str, model=\"gpt-4o-mini\"):\n",
    "    \"\"\"Count tokens using tiktoken for a given model.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def split_text_into_chunks(text: str, max_tokens: int = TOKEN_THRESHOLD, overlap: int = 100) -> list:\n",
    "    \"\"\"\n",
    "    Split a long text into overlapping chunks based on token count.\n",
    "    Uses tiktoken for accurate token counting.\n",
    "    \"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = start + max_tokens\n",
    "        chunk = encoding.decode(tokens[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap  # add overlap for context continuity\n",
    "    return chunks\n",
    "# --------------------------\n",
    "# Relevance Check for Each Chunk\n",
    "# --------------------------\n",
    "\n",
    "def check_chunk_relevance(chunk_text: str, image_query: str) -> bool:\n",
    "    \"\"\"\n",
    "    Ask GPT-4 if a given chunk (section) is relevant to the client's image.\n",
    "    Returns True if the answer starts with \"yes\".\n",
    "    \"\"\"\n",
    "    system_message = f\"\"\"\n",
    "    You are an expert in PCI-DSS compliance. \n",
    "    You are given a section extracted from the PCI-DSS Report on Compliance Template containing the controls and requirements.\n",
    "    A client has provided a screenshot showing details of their network and security configuration.\n",
    "    Analyze the image and identify which specific control requirement is being addressed.\n",
    "    Please be specific in your mapping.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in PCI-DSS compliance.\n",
    "    Below is a section from the PCI-DSS Report on Compliance Template:\n",
    "    \n",
    "    \\\"\\\"\\\"{chunk_text}\\\"\\\"\\\"\n",
    "    \n",
    "    Also, consider the following text extracted from a client's screenshot:\n",
    "    \\\"\\\"\\\"{image_query}\\\"\\\"\\\"\n",
    "\n",
    "    Task:\n",
    "    1. Does this image provide evidence for a specific control(s) and/or \n",
    "    requirements in this section?\n",
    "    2. Identify the EXACT control references from text.\n",
    "    3. Match image features to control requirements.\n",
    "\n",
    "    Is this section relevant to mapping the client's network/security information (from the screenshot) to a PCI-DSS control?\n",
    "    Identify if the image shows implementation of ANY control from this section.\n",
    "     \n",
    "    Answer with a single word: \"Yes\" or \"No\".\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\", \n",
    "            messages=messages,\n",
    "            max_tokens=10,\n",
    "            temperature=0  # deterministic\n",
    "        )\n",
    "        answer = response.choices[0].message.content.strip().lower()\n",
    "        return answer.startswith(\"yes\")\n",
    "    except Exception as e:\n",
    "        print(f\"Relevance check error: {e}\")\n",
    "        return False\n",
    "\n",
    "# --------------------------\n",
    "# Final Mapping Call\n",
    "# --------------------------\n",
    "\n",
    "def map_chunk_to_control(aggregated_context: str, image_path: str, image_text: str) -> str:\n",
    "    \"\"\"\n",
    "    Use the aggregated context (all relevant sections), the OCR text, and the image\n",
    "    to have GPT-4 Vision map the screenshot to specific PCI-DSS rule(s).\n",
    "    \"\"\"\n",
    "    system_message = f\"\"\"\n",
    "    You are an expert in PCI-DSS compliance. \n",
    "    You are given a section extracted from the PCI-DSS Report on Compliance Template containing the controls and requirements.\n",
    "    A client has provided a screenshot showing details of their network and security configuration.\n",
    "    Analyze the image and identify which specific control requirement is being addressed.\n",
    "    Please be specific in your mapping.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in PCI-DSS compliance.\n",
    "    Below is the full context from the PCI-DSS Report on Compliance Template (all sections containing specific rules):\n",
    "    {aggregated_context}\n",
    "    \n",
    "    Also, here is text extracted from a client's network/security screenshot:\n",
    "    {image_text}\n",
    "    \n",
    "    Provide only the control requirement code(s) (e.g., \"Requirement 1.1.1\") and a brief explanation.\n",
    "    Do not include any extraneous text.\n",
    "    \"\"\"\n",
    "    image_data_url = image_to_data_url(image_path)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": image_data_url}}\n",
    "        ]}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",  \n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# --------------------------\n",
    "# Main Application Flow\n",
    "# --------------------------\n",
    "\n",
    "def main():\n",
    "    pdf_path = \"PCI-DSS-ROC-Template.pdf\"       # Path to your PCI-DSS ROC PDF\n",
    "    image_path = \"Connfido Network Diagram.png\"  # Client screenshot image path\n",
    "\n",
    "    print(\"Processing PDF and loading cached sections...\")\n",
    "    processed_sections = load_or_process_pdf(pdf_path)\n",
    "    if not processed_sections:\n",
    "        print(\"No processed sections found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"Found sections:\")\n",
    "    for title in processed_sections:\n",
    "        print(f\"--- {title} ---\")\n",
    "\n",
    "    print(\"Extracting OCR text from image...\")\n",
    "    image_query = ocr_image(image_path)\n",
    "\n",
    "    mapped_controls = []\n",
    "    # Loop over each section and its sub-chunks\n",
    "    for title, chunk_list in processed_sections.items():\n",
    "        for chunk in chunk_list:\n",
    "            # Check if this chunk is relevant\n",
    "            if check_chunk_relevance(chunk, image_query):\n",
    "                print(f\"Chunk from section '{title}' is relevant. Mapping control...\")\n",
    "                mapping = map_chunk_to_control(chunk, image_path, image_query)\n",
    "                if mapping:\n",
    "                    mapped_controls.append(mapping)\n",
    "\n",
    "    if not mapped_controls:\n",
    "        print(\"No mapped controls found for the given image. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Aggregate only the mapping outputs (control codes and explanations)\n",
    "    aggregated_mapping = \"\\n\".join(mapped_controls)\n",
    "    print(\"Aggregated Mapped Controls:\")\n",
    "    print(aggregated_mapping)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4d6e54c-f53f-4b32-8f46-e3b74df7e3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF and loading cached sections...\n",
      "Loaded cached processed PDF sections.\n",
      "Found sections:\n",
      "--- General ---\n",
      "--- PCI DSS 4.0 ---\n",
      "--- DO: ---\n",
      "--- DON’T: ---\n",
      "--- DSS. ---\n",
      "--- OR • ---\n",
      "--- CDE. ---\n",
      "--- IDS/IPS. ---\n",
      "--- FIM. ---\n",
      "--- OR ---\n",
      "Extracting OCR text from image...\n",
      "Chunk from section 'General' is relevant. Mapping control...\n",
      "Chunk from section 'PCI DSS 4.0' is relevant. Mapping control...\n",
      "Chunk from section 'DO:' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'DSS.' is relevant. Mapping control...\n",
      "Chunk from section 'OR •' is relevant. Mapping control...\n",
      "Chunk from section 'OR •' is relevant. Mapping control...\n",
      "Chunk from section 'OR •' is relevant. Mapping control...\n",
      "Chunk from section 'CDE.' is relevant. Mapping control...\n",
      "Chunk from section 'CDE.' is relevant. Mapping control...\n",
      "Chunk from section 'IDS/IPS.' is relevant. Mapping control...\n",
      "Chunk from section 'IDS/IPS.' is relevant. Mapping control...\n",
      "Chunk from section 'FIM.' is relevant. Mapping control...\n",
      "Chunk from section 'OR' is relevant. Mapping control...\n",
      "Chunk from section 'OR' is relevant. Mapping control...\n",
      "Chunk from section 'OR' is relevant. Mapping control...\n",
      "Aggregated Mapped Controls:\n",
      "Requirement 1.1.3: Network diagrams include all connections to cardholder data, and critical components for PCI DSS compliance.\n",
      "\n",
      "Requirement 4.1: Use strong cryptography and security protocols (e.g., TLS v1.2 or above) to safeguard sensitive cardholder data during transmission.\n",
      "Requirement 1.1.3\n",
      "\n",
      "Network Diagram - The diagram shows the segmentation of the network with components such as Virtual Networks (VNET), Load Balancers, and specific IP ranges, which addresses the requirement to diagram all network connections to cardholder data (CDE).\n",
      "Requirement 1.1.2\n",
      "\n",
      "The network diagram provided is an example of a current diagram that accurately reflects the cardholder data flows and security zones, as required by the PCI-DSS for understanding data flows and connections.\n",
      "Requirement 1.1.3: The network diagram in the screenshot shows the connectivity, which addresses having current network diagrams that identify all connections between the cardholder data environment and other networks, including any wireless networks.\n",
      "Requirement 1.2.3\n",
      "\n",
      "The network diagram shows all connections between the Cardholder Data Environment (CDE) and other networks, which addresses the requirement to maintain accurate network diagrams.\n",
      "Requirement 2.2.7\n",
      "\n",
      "Non-console administrative access is encrypted using strong cryptography (e.g., TLS v1.2 or above).\n",
      "Requirement 3.4.1: The diagram indicates the use of masking and protecting PAN (Primary Account Number) data through TLS v1.2, showing compliance with secure transmission and access control within a secure network.\n",
      "Requirement 4.1.1: The network diagram indicates usage of TLS v1.2 or above for secure transmission, aligning with the requirement for strong cryptography during data transmission.\n",
      "Requirement 6.4.1\n",
      "\n",
      "The network diagram showing the use of TLS v1.2 or above for secure communication is related to protecting public-facing web applications against known attacks and vulnerabilities.\n",
      "Requirement 6.4.1\n",
      "\n",
      "The network diagram shows the deployment of automated technical solutions that detect and block web-based attacks in front of public-facing web applications, satisfying the requirement to protect such applications.\n",
      "Requirement 8.1.2\n",
      "\n",
      "Explanation: The network diagram indicates segregation of roles and responsibilities, aligning with documentation and assignment of these roles as per PCI DSS Requirement 8.1.2.\n",
      "Requirement 1.2.1\n",
      "\n",
      "Explanation: The diagram involves the use of network segmentation through virtual networks (VNETs) and network security groups (NSGs), restricting network access to the cardholder data environment (CDE), which aligns with the requirement to restrict inbound and outbound traffic to only that which is necessary.\n",
      "Requirement 9.3.2.c\n",
      "\n",
      "The network diagram demonstrates the use of secure network segments in Azure and virtual private networks (VPNs), which aligns with requirements for secure access and visitor management within the Cardholder Data Environment (CDE).\n",
      "Requirement 10.6.1: System clocks and time are synchronized using time-synchronization technology. \n",
      "\n",
      "This is addressed by the presence of NTP (Network Time Protocol) servers in the network diagram, ensuring synchronized time settings across all systems.\n",
      "Requirement 1.2.3: Use of Virtual Network (VNET) for segmentation.\n",
      "\n",
      "Requirement 11.2.1: Regular monitoring of authorized and unauthorized wireless access points using network segmentation.\n",
      "Requirement 11.5.1: The network diagram indicates traffic is monitored at various points within the CDE using TLS, which aligns with the requirement to monitor all traffic at the perimeter and critical points in the Cardholder Data Environment (CDE) for intrusion-detection and/or prevention purposes.\n",
      "Requirement 1.1.2\n",
      "\n",
      "Explanation: This requirement involves creating and maintaining a network diagram that identifies all connections between the cardholder data environment (CDE) and other networks, including any wireless networks. The provided network diagram illustrates these connections, supporting compliance with this requirement.\n",
      "Requirement 1.2.3\n",
      "\n",
      "Explanation: The diagram appears to include network segmentation and firewalls to restrict inbound and outbound traffic to secure environments, aligning with the requirement to install and configure a firewall at each Internet connection and between any demilitarized zone (DMZ) and the internal network zone.\n",
      "Requirement 12.8.1\n",
      "\n",
      "The diagram displays details about network segmentation with virtual networks (VNETs), maintaining a list of third-party service providers using different environments for various services.\n",
      "- **Requirement A2.1.1**: TLS v1.2 is used, confirming the entity's devices are not susceptible to any known SSL/early TLS exploits.\n",
      "- **Requirement A1.1.4**: The diagram suggests logical separation, which may relate to the requirement for verifying logical separation controls through penetration testing.\n",
      "- **Requirement A1.2.1**: The use of audit log capability, as systems appear segmented and designated (e.g., Card Data Environment), aligns with secure logging practices.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    pdf_path = \"PCI-DSS-ROC-Template.pdf\"       # Path to your PCI-DSS ROC PDF\n",
    "    image_path = \"Connfido Network Diagram.png\"  # Client screenshot image path\n",
    "\n",
    "    print(\"Processing PDF and loading cached sections...\")\n",
    "    processed_sections = load_or_process_pdf(pdf_path)\n",
    "    if not processed_sections:\n",
    "        print(\"No processed sections found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"Found sections:\")\n",
    "    for title in processed_sections:\n",
    "        print(f\"--- {title} ---\")\n",
    "\n",
    "    print(\"Extracting OCR text from image...\")\n",
    "    image_query = ocr_image(image_path)\n",
    "\n",
    "    mapped_controls = []\n",
    "    # Loop over each section and its sub-chunks\n",
    "    for title, chunk_list in processed_sections.items():\n",
    "        for chunk in chunk_list:\n",
    "            if check_chunk_relevance(chunk, image_query):\n",
    "                print(f\"Chunk from section '{title}' is relevant. Mapping control...\")\n",
    "                mapping = map_chunk_to_control(chunk, image_path, image_query)\n",
    "                if mapping:\n",
    "                    mapped_controls.append(mapping)\n",
    "\n",
    "    if not mapped_controls:\n",
    "        print(\"No mapped controls found for the given image. Exiting.\")\n",
    "        return\n",
    "\n",
    "    # Deduplicate the mapping outputs (preserving order)\n",
    "    unique_mapped_controls = list(dict.fromkeys(mapped_controls))\n",
    "    aggregated_mapping = \"\\n\".join(unique_mapped_controls)\n",
    "    print(\"Aggregated Mapped Controls:\")\n",
    "    print(aggregated_mapping)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b458e232-c2db-447e-9bcb-d4dcece6f89e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48cd05a-02a8-450c-9070-582e8ff19893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037afbdc-5d3f-4ece-b6f5-aa0970dd087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": f\"\"\"\n",
    "            PCI-DSS Section: {chunk['title']}\n",
    "            Document Text: {chunk['text'][:20000]}\n",
    "            Image Context: {ocr_text}\n",
    "\n",
    "            Task:\n",
    "            1. Does this image provide evidence for a specific control(s) and/or \n",
    "            requirements in this section?\n",
    "            2. Identify the EXACT control references from text.\n",
    "            3. Match image features to control requirements.\n",
    "            \n",
    "            Identify if the image shows implementation of ANY control from this section.\n",
    "            Respond ONLY with matching control/requirement number, name, and description (e.g., '7.1 Processes and mechanisms for restricting access to system components and cardholder data by business need to know are defined and understood.') or 'None'\"\"\"},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": image_data}}\n",
    "\n",
    "        ]\n",
    "    }])\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are an expert in PCI-DSS compliance. \n",
    "You are given a section extracted from the PCI-DSS Report on Compliance Template containing the controls and requirements.\n",
    "A client has provided a screenshot showing details of their network and security configuration.\n",
    "Analyze the image and identify which specific control requirement is being addressed.\n",
    "Provide the control requirement code along with a detailed explanation of \n",
    "how the information in the given image satisfies that requirement.\n",
    "Please be as specific as possible in your mapping.\n",
    "\"\"\"\n",
    "    \n",
    "detailed_response = client.chat.completions.create(\n",
    "model=\"gpt-4o\",\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": prompt},\n",
    "    {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": [\n",
    "        {\"type\": \"text\", \"text\": f\"\"\"\n",
    "        Potential Controls: {', '.join(controls)}\n",
    "        Full OCR Text: {ocr_text}\n",
    "        \n",
    "        Generate final mapping report with:\n",
    "        1. Controls/requirements from the PCI-DSS standard\n",
    "        2. Implementation evidence from the image\n",
    "        3. Relevant requirement text from document\"\"\"},\n",
    "        {\"type\": \"image_url\", \"image_url\": {\"url\": image_data}}\n",
    "    ]\n",
    "    }])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a53eb1b8-1330-4051-a350-c17a10cdbfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "def main():\n",
    "    # First run - processes and caches PDF\n",
    "    get_pdf_chunks()  \n",
    "    \n",
    "    # Process multiple images\n",
    "    for img in [\"card_decryption_flow.jpg\"]:\n",
    "        print(f\"\\nProcessing {img}...\")\n",
    "        print(process_image(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f149abc4-ad62-4e87-99ea-48af8cb7a8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b015dd8c-5a09-4419-a89d-8bdf2a1bf12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze section of the document to map given image\n",
    "def analyze_section(section: dict, image_data_url: str, ocr_text: str) -> dict:\n",
    "    \"\"\"Analyze one document section with image context\"\"\"\n",
    "    instruct_prompt = f\"\"\"\n",
    "    PCI-DSS Document Section Analysis\n",
    "    Section Title: {section['title']}\n",
    "    Section Content: {section['content'][:2500]}\n",
    "    \n",
    "    OCR Context from Image: {ocr_text}\n",
    "    \n",
    "    Task:\n",
    "    1. Does this image provide evidence for this specific control?\n",
    "    2. Identify EXACT control references from text\n",
    "    3. Match image features to control requirements\n",
    "    \n",
    "    Respond STRICTLY in format:\n",
    "    Relevant: [Yes/No]\n",
    "    Control: [exact control text from document]\n",
    "    Match Confidence: [High/Medium/Low]\n",
    "    Evidence: [specific matching details from image]\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert in PCI-DSS compliance. \n",
    "    You are given a section extracted from the PCI-DSS Report on Compliance Template containing the controls and requirements.\n",
    "    A client has provided a screenshot showing details of their network and security configuration.\n",
    "    Analyze the image and identify which specific control requirement is being addressed.\n",
    "    Provide the control requirement code along with a detailed explanation of \n",
    "    how the information in the given image satisfies that requirement.\n",
    "    Please be as specific as possible in your mapping.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": instruct_prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": image_data_url}}\n",
    "                ]}\n",
    "            ],\n",
    "            max_tokens=400\n",
    "        )\n",
    "        return parse_response(response.choices[0].message.content, section)\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing section: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3cb7a0e-d0ff-4f46-8f96-fd806a1d3efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(response: str, section: dict) -> dict:\n",
    "    lines = response.split(\"\\n\")\n",
    "    result = {\n",
    "        \"relevant\": False,\n",
    "        \"control\": \"\",\n",
    "        \"confidence\": \"\",\n",
    "        \"evidence\": \"\",\n",
    "        \"section_title\": section[\"title\"],\n",
    "        \"section_content\": section[\"content\"][:1000] + \"...\" \n",
    "    }\n",
    "    \n",
    "    for line in lines:\n",
    "        if \"Relevant: Yes\" in line:\n",
    "            result[\"relevant\"] = True\n",
    "        elif \"Control:\" in line:\n",
    "            result[\"control\"] = line.split(\"Control:\")[-1].strip()\n",
    "        elif \"Match Confidence:\" in line:\n",
    "            result[\"confidence\"] = line.split(\"Match Confidence:\")[-1].strip()\n",
    "        elif \"Evidence:\" in line:\n",
    "            result[\"evidence\"] = line.split(\"Evidence:\")[-1].strip()\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f17a2f7f-7230-434e-9919-0ee9140503fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_results(findings: list, image_data_url: str) -> str:\n",
    "    \"\"\"Final validation with all positive matches\"\"\"\n",
    "    validation_prompt = \"\"\"\n",
    "    Cross-Validate PCI-DSS Matches\n",
    "    \n",
    "    Positive Matches:\n",
    "    \"\"\" + \"\\n\".join(\n",
    "        f\"{i+1}. {f['control']} (Confidence: {f['confidence']})\"\n",
    "        for i, f in enumerate(findings)\n",
    "    ) + \"\"\"\n",
    "    \n",
    "    Task:\n",
    "    1. Eliminate false positives\n",
    "    2. Rank matches by relevance\n",
    "    3. Combine supporting evidence\n",
    "    4. Cite exact requirement text\n",
    "    \n",
    "    Final report format:\n",
    "    ## PCI-DSS Compliance Mapping\n",
    "    **Primary Control**: [control code] - [description]\n",
    "    - Image Evidence: [specific features]\n",
    "    - Document Reference: [exact text snippet]\n",
    "    - Compliance Status: [Met/Partial/Not Met]\n",
    "    \n",
    "    [Repeat for secondary controls]\"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a senior PCI-DSS auditor.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": validation_prompt},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": image_data_url}}\n",
    "            ]}\n",
    "        ],\n",
    "        max_tokens=600\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "202376ce-da48-4a39-812d-fcfc9b58f689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    pdf_path = \"PCI-DSS-ROC-Template.pdf\"\n",
    "    image_path = \"Connfido Network Diagram.png\"\n",
    "    \n",
    "    print(\"Processing document structure...\")\n",
    "    sections = extract_sections_from_pdf(pdf_path)\n",
    "    print(f\"Identified {len(sections)} logical sections\")\n",
    "    \n",
    "    ocr_text = ocr_image(image_path)\n",
    "    image_data_url = image_to_data_url(image_path)\n",
    "    \n",
    "    findings = []\n",
    "    for idx, section in enumerate(sections):\n",
    "        print(f\"Analyzing section {idx+1}/{len(sections)}: {section['title'][:50]}...\")\n",
    "        result = analyze_section(section, image_data_url, ocr_text)\n",
    "        if result and result[\"relevant\"]:\n",
    "            findings.append(result)\n",
    "    \n",
    "    if findings:\n",
    "        print(\"\\nCross-validating results...\")\n",
    "        final_report = cross_validate_results(findings, image_data_url)\n",
    "        print(\"\\nFINAL COMPLIANCE MAPPING:\")\n",
    "        print(final_report)\n",
    "    else:\n",
    "        print(\"No PCI-DSS controls matched to the image content\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45f84ac8-d871-41f6-bfa3-08d26544e9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing document structure...\n",
      "Identified 1 logical sections\n",
      "Analyzing section 1/1: Document Start...\n",
      "\n",
      "Cross-validating results...\n",
      "\n",
      "FINAL COMPLIANCE MAPPING:\n",
      "## PCI-DSS Compliance Mapping\n",
      "\n",
      "**Primary Control**: 4.1 - Use strong cryptography and security protocols to protect sensitive cardholder data during transmission over open, public networks.\n",
      "\n",
      "- **Image Evidence**: The image shows network diagrams, which seem to include components indicating encryption protocols, such as VPNs or SSL/TLS labels. The lines between systems might denote encrypted communication paths.\n",
      "\n",
      "- **Document Reference**: \"Use strong cryptography and security protocols to protect sensitive cardholder data during transmission over open, public networks.\"\n",
      "\n",
      "- **Compliance Status**: Met\n",
      "\n",
      "**Secondary Control**: (If applicable, repeat the format above for additional controls identified in the documentation or network diagram.)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f5b361-3a25-4e20-969b-a80727e6f141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "661d4aac-af5e-4a34-a0a0-844a37286db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF and loading cached sections...\n",
      "Section 'General' is very large (150575 tokens); splitting further.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "merge_small_chunks() got an unexpected keyword argument 'min_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 316\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplanation: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdetails[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexplanation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 316\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 280\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    277\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnfido Network Diagram.png\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Client screenshot image path\u001b[39;00m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing PDF and loading cached sections...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 280\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[43mload_or_process_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunks:\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo processed sections found. Exiting.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 131\u001b[0m, in \u001b[0;36mload_or_process_pdf\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded cached processed PDF sections.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 131\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_sections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(CHUNKS_CACHE_FILE, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    133\u001b[0m         json\u001b[38;5;241m.\u001b[39mdump(chunks, f, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn[1], line 112\u001b[0m, in \u001b[0;36mprocess_sections\u001b[1;34m(pdf_path)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSection \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msection[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is very large (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokens\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m tokens); splitting further.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    111\u001b[0m sub_chunks \u001b[38;5;241m=\u001b[39m split_text_into_chunks(full_text, max_tokens\u001b[38;5;241m=\u001b[39mTOKEN_THRESHOLD, overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m--> 112\u001b[0m merged_chunks \u001b[38;5;241m=\u001b[39m \u001b[43mmerge_small_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_chunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMIN_CHUNK_TOKENS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m merged_chunks:\n\u001b[0;32m    114\u001b[0m     all_chunks\u001b[38;5;241m.\u001b[39mappend({\n\u001b[0;32m    115\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m: section[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: chunk,\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m\"\u001b[39m: count_tokens(chunk)\n\u001b[0;32m    118\u001b[0m     })\n",
      "\u001b[1;31mTypeError\u001b[0m: merge_small_chunks() got an unexpected keyword argument 'min_tokens'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from mimetypes import guess_type\n",
    "from PIL import Image\n",
    "import fitz\n",
    "import pytesseract\n",
    "import tiktoken\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "\n",
    "# Configuration\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"  # Set your API key\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "CHUNKS_CACHE_FILE = \"pci_processed_chunks.json\"\n",
    "TOKEN_THRESHOLD = 10000\n",
    "MIN_CHUNK_TOKENS = 300  # Minimum tokens per chunk before merging\n",
    "\n",
    "# --------------------------\n",
    "# PDF Processing Utilities\n",
    "# --------------------------\n",
    "\n",
    "def partition_pdf_by_title(pdf_path):\n",
    "    \"\"\"\n",
    "    Partition the PDF into ordered sections with titles using metadata.\n",
    "    Returns a list of dicts: [{'title': <str>, 'content': <str>}, ...]\n",
    "    \"\"\"\n",
    "    elements = partition_pdf(filename=pdf_path)\n",
    "    sections = []\n",
    "    current_title = \"General\"\n",
    "    current_content = []\n",
    "    \n",
    "    for element in elements:\n",
    "        text = element.text.strip()\n",
    "        category = getattr(element.metadata, \"category\", \"\") if element.metadata else \"\"\n",
    "        \n",
    "        if category in [\"Title\", \"Header\"]:\n",
    "            if current_content:\n",
    "                sections.append({\n",
    "                    \"title\": current_title,\n",
    "                    \"content\": \"\\n\".join(current_content)\n",
    "                })\n",
    "                current_content = []\n",
    "            current_title = text\n",
    "        else:\n",
    "            current_content.append(text)\n",
    "    \n",
    "    if current_content:\n",
    "        sections.append({\n",
    "            \"title\": current_title,\n",
    "            \"content\": \"\\n\".join(current_content)\n",
    "        })\n",
    "    \n",
    "    return sections\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"Count tokens using tiktoken.\"\"\"\n",
    "    return len(tiktoken.get_encoding(\"cl100k_base\").encode(text))\n",
    "\n",
    "\n",
    "def split_text_into_chunks(text: str, max_tokens: int = TOKEN_THRESHOLD, overlap: int = 100) -> list:\n",
    "    \"\"\"Split text into overlapping chunks based on token count.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text)\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(tokens):\n",
    "        end = start + max_tokens\n",
    "        chunk = encoding.decode(tokens[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap  # maintain overlap for continuity\n",
    "    return chunks\n",
    "\n",
    "def merge_small_chunks(chunks: list, min_tokens: int = MIN_CHUNK_TOKENS) -> list:\n",
    "    \"\"\"Merge adjacent chunks if a chunk is very small.\"\"\"\n",
    "    merged = []\n",
    "    encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    i = 0\n",
    "    while i < len(chunks):\n",
    "        current = chunks[i]\n",
    "        current_tokens = len(encoding.encode(current))\n",
    "        if current_tokens < min_tokens and i + 1 < len(chunks):\n",
    "            merged_chunk = current + \"\\n\" + chunks[i+1]\n",
    "            merged.append(merged_chunk)\n",
    "            i += 2\n",
    "        else:\n",
    "            merged.append(current)\n",
    "            i += 1\n",
    "    return merged\n",
    "\n",
    "def process_sections(pdf_path):\n",
    "    \"\"\"\n",
    "    Partition the PDF by title and, for each section that exceeds TOKEN_THRESHOLD,\n",
    "    split it into sub-chunks and merge small chunks.\n",
    "    Returns a list of dicts: [{'title': <str>, 'text': <str>}, ...]\n",
    "    \"\"\"\n",
    "    raw_sections = partition_pdf_by_title(pdf_path)\n",
    "    all_chunks = []\n",
    "    for section in raw_sections:\n",
    "        full_text = f\"{section['title']}\\n{section['content']}\"\n",
    "        tokens = count_tokens(full_text)\n",
    "        if tokens <= TOKEN_THRESHOLD:\n",
    "            all_chunks.append({\n",
    "                \"title\": section['title'],\n",
    "                \"text\": full_text,\n",
    "                \"tokens\": tokens\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Section '{section['title']}' is very large ({tokens} tokens); splitting further.\")\n",
    "            sub_chunks = split_text_into_chunks(full_text, max_tokens=TOKEN_THRESHOLD, overlap=100)\n",
    "            merged_chunks = merge_small_chunks(sub_chunks, min_tokens=MIN_CHUNK_TOKENS)\n",
    "            for chunk in merged_chunks:\n",
    "                all_chunks.append({\n",
    "                    \"title\": section['title'],\n",
    "                    \"text\": chunk,\n",
    "                    \"tokens\": count_tokens(chunk)\n",
    "                })\n",
    "    return all_chunks\n",
    "\n",
    "\n",
    "def load_or_process_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Load cached processed PDF sections if available; otherwise, process the PDF and cache the result.\n",
    "    Expected cache format: list of dicts with keys \"title\" and \"text\".\n",
    "    \"\"\"\n",
    "    if os.path.exists(CHUNKS_CACHE_FILE):\n",
    "        with open(CHUNKS_CACHE_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            chunks = json.load(f)\n",
    "        print(\"Loaded cached processed PDF sections.\")\n",
    "    else:\n",
    "        chunks = process_sections(pdf_path)\n",
    "        with open(CHUNKS_CACHE_FILE, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(chunks, f, ensure_ascii=False, indent=2)\n",
    "        print(\"Processed PDF and saved cache.\")\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Image Processing\n",
    "# --------------------------\n",
    "\n",
    "def ocr_image(image_path):\n",
    "    \"\"\"Extract text from an image using pytesseract.\"\"\"\n",
    "    image = Image.open(image_path)\n",
    "    return pytesseract.image_to_string(image)\n",
    "\n",
    "def image_to_data_url(image_path: str) -> str:\n",
    "    \"\"\"Convert an image file to a base64-encoded data URL.\"\"\"\n",
    "    mime_type, _ = guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = 'image/png'\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        encoded = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "    return f\"data:{mime_type};base64,{encoded}\"\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# API Interaction Handlers\n",
    "# --------------------------\n",
    "\n",
    "def check_chunk_relevance(chunk_text: str, image_ocr: str) -> bool:\n",
    "    \"\"\"Determine if chunk is relevant using GPT-4 with batch optimization.\"\"\"\n",
    "    \n",
    "    system_message = f\"\"\"\n",
    "    You are an expert in PCI-DSS compliance. \n",
    "    Analyze if the document section contains PCI-DSS controls relevant to the information in the given image.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Document chunk:\n",
    "    \\\"\\\"\\\"{chunk_text}\\\"\\\"\\\"\n",
    "    \n",
    "    Client screenshot text:\n",
    "    \\\"\\\"\\\"{image_ocr}\\\"\\\"\\\"\n",
    "    \n",
    "    Is this chunk relevant for mapping the client's network/security information to a PCI-DSS control? \n",
    "    Answer only \"Yes\" or \"No\".\n",
    "    \"\"\"\n",
    "    messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message}, \n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            max_tokens=10,\n",
    "            temperature=0\n",
    "        )\n",
    "        answer = response.choices[0].message.content.strip().lower()\n",
    "        return answer.startswith(\"yes\")\n",
    "    except Exception as e:\n",
    "        print(f\"Relevance check error: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def map_chunk_to_control(chunk_text: str, image_ocr: str, image_path: str) -> dict:\n",
    "    \"\"\"Get structured control mappings from GPT-4 Vision.\"\"\"\n",
    "\n",
    "    system_message = \"You are an expert in PCI-DSS compliance.\"\n",
    "    prompt = f\"\"\"\n",
    "    Document chunk:\n",
    "    \\\"\\\"\\\"{chunk_text}\\\"\\\"\\\"\n",
    "    \n",
    "    Client screenshot text:\n",
    "    \\\"\\\"\\\"{image_ocr}\\\"\\\"\\\"\n",
    "    \n",
    "    Based solely on the above, identify which specific control requirement the screenshot addresses.\n",
    "    Return your answer as a single-line JSON object with exactly these keys:\n",
    "      \"control_code\": string (e.g., \"Requirement 1.1.2a\"),\n",
    "      \"description\": string (an excerpt from the document describing the requirement),\n",
    "      \"explanation\": string (a brief explanation of why the image satisfies this requirement).\n",
    "    If no control applies, return empty JSON object.\n",
    "    Output only the JSON with no extra text.\n",
    "    \"\"\"\n",
    "    image_data_url = image_to_data_url(image_path)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"text\", \"text\": prompt},\n",
    "            {\"type\": \"image_url\", \"image_url\": {\"url\": image_data_url}}\n",
    "        ]}\n",
    "    ]\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=messages,\n",
    "            max_tokens=200,\n",
    "            temperature=0.2\n",
    "        )\n",
    "        output = response.choices[0].message.content.strip()\n",
    "        print(\"Raw mapping output:\", output)  # Debug print\n",
    "        if not output:\n",
    "            return {}\n",
    "        mapping = json.loads(output)\n",
    "        if mapping.get(\"control_code\"):\n",
    "            return mapping\n",
    "        else:\n",
    "            return {}\n",
    "    except Exception as e:\n",
    "        print(f\"Mapping error for chunk: {e}\")\n",
    "        return {}\n",
    "\n",
    "# --------------------------\n",
    "# Aggregation and Deduplication\n",
    "# --------------------------\n",
    "\n",
    "def aggregate_mappings(mappings: list) -> dict:\n",
    "    \"\"\"\n",
    "    Aggregate a list of mapping dictionaries into a deduplicated dict keyed by control code.\n",
    "    Merge explanations for duplicate control codes.\n",
    "    \"\"\"\n",
    "    aggregated = {}\n",
    "    for mapping in mappings:\n",
    "        code = mapping.get(\"control_code\")\n",
    "        if not code:\n",
    "            continue\n",
    "        if code in aggregated:\n",
    "            existing_expl = aggregated[code][\"explanation\"]\n",
    "            new_expl = mapping.get(\"explanation\", \"\")\n",
    "            if new_expl and new_expl not in existing_expl:\n",
    "                aggregated[code][\"explanation\"] += \" \" + new_expl\n",
    "        else:\n",
    "            aggregated[code] = {\n",
    "                \"description\": mapping.get(\"description\", \"\"),\n",
    "                \"explanation\": mapping.get(\"explanation\", \"\")\n",
    "            }\n",
    "    return aggregated\n",
    "\n",
    "# --------------------------\n",
    "# Main Workflow\n",
    "# --------------------------\n",
    "\n",
    "def main():\n",
    "    pdf_path = \"PCI-DSS-ROC-Template.pdf\"       # Path to your PCI-DSS ROC PDF\n",
    "    image_path = \"Connfido Network Diagram.png\"  # Client screenshot image path\n",
    "\n",
    "    print(\"Processing PDF and loading cached sections...\")\n",
    "    chunks = load_or_process_pdf(pdf_path)\n",
    "    if not chunks:\n",
    "        print(\"No processed sections found. Exiting.\")\n",
    "        return\n",
    "\n",
    "    print(\"Found sections:\")\n",
    "    for item in chunks:\n",
    "        print(f\"--- {item['title']} ---\")\n",
    "\n",
    "    print(\"Extracting OCR text from image...\")\n",
    "    image_ocr = ocr_image(image_path)\n",
    "\n",
    "    mapping_outputs = []\n",
    "    # Loop over each chunk in the processed sections\n",
    "    for item in chunks:\n",
    "        text = item['text']\n",
    "        if not text.strip():\n",
    "            continue\n",
    "        if check_chunk_relevance(text, image_ocr):\n",
    "            print(f\"Chunk from section '{item['title']}' is relevant. Mapping control...\")\n",
    "            mapping = map_chunk_to_control(text, image_ocr, image_path)\n",
    "            if mapping and mapping.get(\"control_code\"):\n",
    "                mapping_outputs.append(mapping)\n",
    "\n",
    "    if not mapping_outputs:\n",
    "        print(\"No mapped controls found for the given image. Exiting.\")\n",
    "        return\n",
    "\n",
    "    aggregated = aggregate_mappings(mapping_outputs)\n",
    "    print(\"Final Aggregated Mapped Controls:\")\n",
    "    for code, details in aggregated.items():\n",
    "        print(f\"\\nControl: {code}\")\n",
    "        print(f\"Description: {details['description']}\")\n",
    "        print(f\"Explanation: {details['explanation']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7fc1a-157b-41e2-938e-7f2b9b6139a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lang-env]",
   "language": "python",
   "name": "conda-env-lang-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
